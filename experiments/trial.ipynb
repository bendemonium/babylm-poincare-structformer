{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c18cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "class StructformerConfig(PretrainedConfig):\n",
    "    model_type = \"structformer\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        max_length: int = 128,\n",
    "        vocab_size: int = 50257,\n",
    "        c: float = 1.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.max_length = max_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.c = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b181224",
   "metadata": {},
   "outputs": [],
   "source": [
    "spdefault_config = StructformerConfig()\n",
    "spdefault_config.save_pretrained(\"custom_structformer_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d371e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def mobius_add(x, y, c=1.0):\n",
    "    # Möbius addition on the Poincaré ball\n",
    "    norm_x = jnp.linalg.norm(x, axis=-1, keepdims=True)\n",
    "    norm_y = jnp.linalg.norm(y, axis=-1, keepdims=True)\n",
    "    dot = jnp.sum(x * y, axis=-1, keepdims=True)\n",
    "    numerator = (1 + 2 * c * dot + c * norm_y ** 2) * x + (1 - c * norm_x ** 2) * y\n",
    "    denominator = 1 + 2 * c * dot + c ** 2 * norm_x ** 2 * norm_y ** 2\n",
    "    return numerator / jnp.clip(denominator, 1e-5, None)\n",
    "\n",
    "def poincare_distance(x, y, c=1.0):\n",
    "    # Compute Poincaré distance between x, y\n",
    "    sqrt_c = jnp.sqrt(c)\n",
    "    diff = x - y\n",
    "    norm_diff = jnp.linalg.norm(diff, axis=-1)\n",
    "    norm_x = jnp.linalg.norm(x, axis=-1)\n",
    "    norm_y = jnp.linalg.norm(y, axis=-1)\n",
    "    num = 2 * sqrt_c * norm_diff\n",
    "    denom = (1 - c * norm_x ** 2) * (1 - c * norm_y ** 2)\n",
    "    return jnp.arccosh(1 + num ** 2 / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc0d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "from typing import Any, Optional\n",
    "from transformers import FlaxPreTrainedModel\n",
    "# from ..models.hyperbolic_layers import mobius_add  # JAX version\n",
    "\n",
    "class PoincareHierarchicalBlock(nn.Module):\n",
    "    hidden_size: int\n",
    "    num_heads: int\n",
    "    c: float = 1.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, mask):\n",
    "        # Flax self-attention: expects shape (batch, seq, hidden)\n",
    "        expanded_mask = jnp.expand_dims(mask, axis=1)  # (batch, 1, seq)\n",
    "        expanded_mask = jnp.expand_dims(expanded_mask, axis=2)  # (batch, 1, 1, seq)\n",
    "        # Flax SelfAttention: deterministic for eval\n",
    "        attn = nn.SelfAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            dtype=x.dtype,\n",
    "            deterministic=True\n",
    "        )(x, mask=expanded_mask)\n",
    "        hyp_output = mobius_add(x, attn, c=self.c)\n",
    "        return hyp_output\n",
    "\n",
    "class StructformerPoincare(nn.Module):\n",
    "    vocab_size: int\n",
    "    hidden_dim: int = 512\n",
    "    num_heads: int = 8\n",
    "    num_layers: int = 6\n",
    "    max_length: int = 128\n",
    "    c: float = 1.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, input_ids, attention_mask):\n",
    "        # Token and position embeddings\n",
    "        token_embed = nn.Embed(self.vocab_size, self.hidden_dim)\n",
    "        pos_embed = self.param(\n",
    "            \"pos_embed\",\n",
    "            nn.initializers.normal(stddev=0.02),\n",
    "            (1, self.max_length, self.hidden_dim),\n",
    "        )\n",
    "        x = token_embed(input_ids) + pos_embed[:, :input_ids.shape[1], :]\n",
    "        # Stacked blocks\n",
    "        for _ in range(self.num_layers):\n",
    "            x = PoincareHierarchicalBlock(self.hidden_dim, self.num_heads, self.c)(x, attention_mask)\n",
    "        x = nn.LayerNorm()(x)\n",
    "        logits = nn.Dense(self.vocab_size)(x)\n",
    "        return logits\n",
    "\n",
    "class StructformerModel(FlaxPreTrainedModel):\n",
    "    module_class = StructformerPoincare\n",
    "    config_class = StructformerConfig\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Any,\n",
    "        input_shape: Optional[tuple] = (1, 128),\n",
    "        seed: int = 0,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Instantiate Flax module\n",
    "        module = self.module_class(\n",
    "            vocab_size=config.vocab_size,\n",
    "            hidden_dim=getattr(config, \"hidden_dim\", 512),\n",
    "            num_heads=getattr(config, \"num_heads\", 8),\n",
    "            num_layers=getattr(config, \"num_layers\", 6),\n",
    "            max_length=getattr(config, \"max_length\", 128),\n",
    "            c=getattr(config, \"c\", 1.0),\n",
    "        )\n",
    "        super().__init__(config, module, input_shape=input_shape, seed=seed, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a3d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, FlaxAutoModel\n",
    "\n",
    "AutoConfig.register(\"structformer\", StructformerConfig)\n",
    "AutoModel.register(StructformerConfig, StructformerModel)\n",
    "FlaxAutoModel.register(StructformerConfig, StructformerModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339dc168",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5421108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "StructformerModel.register_for_auto_class(\"FlaxAutoModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c0e9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339a8e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Send: curl -X HEAD -H 'Accept: */*' -H 'Accept-Encoding: identity' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4' https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/config.json\n",
      "Request 0dad1f02-b6bb-411e-b4b0-9c024890d484: HEAD https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/config.json (authenticated: True)\n",
      "Send: curl -X HEAD -H 'Accept: */*' -H 'Accept-Encoding: identity' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4' https://huggingface.co/api/resolve-cache/models/bendemonium/babylm-poincare-structformer/eda60faed6eb06c5bb7917d88775709a388d59ec/config.json\n",
      "Request 98dfefab-3e43-4d5b-a0cf-1208721875e0: HEAD https://huggingface.co/api/resolve-cache/models/bendemonium/babylm-poincare-structformer/eda60faed6eb06c5bb7917d88775709a388d59ec/config.json (authenticated: True)\n",
      "Downloading 'config.json' to '/Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/blobs/53df94ef4741229252b7915df904d26d493c967c.incomplete'\n",
      "Send: curl -X GET -H 'Accept: */*' -H 'Accept-Encoding: gzip, deflate' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4' https://huggingface.co/api/resolve-cache/models/bendemonium/babylm-poincare-structformer/eda60faed6eb06c5bb7917d88775709a388d59ec/config.json\n",
      "Request 20bf792a-b65d-4b92-bfdb-b0ae840c6102: GET https://huggingface.co/api/resolve-cache/models/bendemonium/babylm-poincare-structformer/eda60faed6eb06c5bb7917d88775709a388d59ec/config.json (authenticated: True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41784c2b250b417ea23e2d2398c6e4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/149 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download complete. Moving file to /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/blobs/53df94ef4741229252b7915df904d26d493c967c\n",
      "Creating pointer from ../../blobs/53df94ef4741229252b7915df904d26d493c967c to /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/snapshots/eda60faed6eb06c5bb7917d88775709a388d59ec/config.json\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Send: curl -X HEAD -H 'Accept: */*' -H 'Accept-Encoding: identity' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4; file_type/model; framework/flax; from_auto_class/False' https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/flax_model.msgpack\n",
      "Request c74a7554-7b06-4f5f-841e-653193cf817d: HEAD https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/flax_model.msgpack (authenticated: True)\n",
      "Send: curl -X HEAD -H 'Accept: */*' -H 'Accept-Encoding: identity' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4; file_type/model; framework/flax; from_auto_class/False' https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/flax_model.msgpack.index.json\n",
      "Request 1c496e46-4a15-4dd9-b4ec-3a2877525779: HEAD https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/flax_model.msgpack.index.json (authenticated: True)\n",
      "Send: curl -X HEAD -H 'Accept: */*' -H 'Accept-Encoding: identity' -H 'Connection: keep-alive' -H 'authorization: <TOKEN>' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4; file_type/model; framework/flax; from_auto_class/False' https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/model.safetensors\n",
      "Request 45390cab-4422-494b-92fc-68553d0c1baf: HEAD https://huggingface.co/bendemonium/babylm-poincare-structformer/resolve/main/model.safetensors (authenticated: True)\n",
      "Downloading 'model.safetensors' to '/Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/blobs/cab33ccc7ada018646f63a905e310c51a1a0e55bf43c98ccc63653d73f54e634.incomplete'\n",
      "Send: curl -X GET -H 'Accept: */*' -H 'Accept-Encoding: gzip, deflate' -H 'Connection: keep-alive' -H 'user-agent: unknown/None; hf_hub/0.34.3; python/3.11.11; torch/2.7.1; transformers/4.54.1; session_id/8ed1f61c4e1147eca9ee3676bc1694a4; file_type/model; framework/flax; from_auto_class/False' 'https://cdn-lfs-us-1.hf.co/repos/99/ed/99ed9a42af9026ed8f72c834d9b5a9347539b97711d4b292d342c1a49cd9d2ab/cab33ccc7ada018646f63a905e310c51a1a0e55bf43c98ccc63653d73f54e634?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1754543722&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NDU0MzcyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk5L2VkLzk5ZWQ5YTQyYWY5MDI2ZWQ4ZjcyYzgzNGQ5YjVhOTM0NzUzOWI5NzcxMWQ0YjI5MmQzNDJjMWE0OWNkOWQyYWIvY2FiMzNjY2M3YWRhMDE4NjQ2ZjYzYTkwNWUzMTBjNTFhMWEwZTU1YmY0M2M5OGNjYzYzNjUzZDczZjU0ZTYzND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=BXWQmldIukZp-Czjv1tjEVsk3DyUfSZrWzaaFfUjbee600iF1Cz8J8vH5ZIvULp9PHCMCF2RWK6qjliHaB1o4lkZNQUdjgoMI6uwCT9sipsds4WQkQ2RdwQxrb1fcsqq1UHf~r9tJtq-fk4t40MHpM4uuOCj2z-0zF8wxF1RK7Sqtd~ZtAINEXhQ9KPoJ4KFqAVE9Zd8~Q~asiB6~slovmkiSRH-m1Dxs1lDeWUOs5XIt3XuWs-QhZ1AZpwcGXuZwbjDz-UuZw~0IAmX2ZkGpjP~XhSngXNiN0~9Slvj4a0D4GRt8KNdd2nmLRZaVqZpOFalu3kVfdBcrJ55dFkKDA__&Key-Pair-Id=K24J24Z295AEI9'\n",
      "Request 456e149a-a27e-486a-af31-b5b1c2463794: GET https://cdn-lfs-us-1.hf.co/repos/99/ed/99ed9a42af9026ed8f72c834d9b5a9347539b97711d4b292d342c1a49cd9d2ab/cab33ccc7ada018646f63a905e310c51a1a0e55bf43c98ccc63653d73f54e634?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1754543722&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NDU0MzcyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk5L2VkLzk5ZWQ5YTQyYWY5MDI2ZWQ4ZjcyYzgzNGQ5YjVhOTM0NzUzOWI5NzcxMWQ0YjI5MmQzNDJjMWE0OWNkOWQyYWIvY2FiMzNjY2M3YWRhMDE4NjQ2ZjYzYTkwNWUzMTBjNTFhMWEwZTU1YmY0M2M5OGNjYzYzNjUzZDczZjU0ZTYzND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=BXWQmldIukZp-Czjv1tjEVsk3DyUfSZrWzaaFfUjbee600iF1Cz8J8vH5ZIvULp9PHCMCF2RWK6qjliHaB1o4lkZNQUdjgoMI6uwCT9sipsds4WQkQ2RdwQxrb1fcsqq1UHf~r9tJtq-fk4t40MHpM4uuOCj2z-0zF8wxF1RK7Sqtd~ZtAINEXhQ9KPoJ4KFqAVE9Zd8~Q~asiB6~slovmkiSRH-m1Dxs1lDeWUOs5XIt3XuWs-QhZ1AZpwcGXuZwbjDz-UuZw~0IAmX2ZkGpjP~XhSngXNiN0~9Slvj4a0D4GRt8KNdd2nmLRZaVqZpOFalu3kVfdBcrJ55dFkKDA__&Key-Pair-Id=K24J24Z295AEI9 (authenticated: False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d297344fd5478fb2c8db3b3a70970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/107M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download complete. Moving file to /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/blobs/cab33ccc7ada018646f63a905e310c51a1a0e55bf43c98ccc63653d73f54e634\n",
      "Creating pointer from ../../blobs/cab33ccc7ada018646f63a905e310c51a1a0e55bf43c98ccc63653d73f54e634 to /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/snapshots/eda60faed6eb06c5bb7917d88775709a388d59ec/model.safetensors\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "The safetensors archive passed at /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/snapshots/eda60faed6eb06c5bb7917d88775709a388d59ec/model.safetensors does not contain the valid metadata. Make sure you save your model with the `save_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlaxAutoModel\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mFlaxAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbendemonium/babylm-poincare-structformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                             \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research/babylm25/babyLM/bb-env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/research/babylm25/babyLM/bb-env/lib/python3.11/site-packages/transformers/modeling_flax_utils.py:888\u001b[39m, in \u001b[36mFlaxPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, dtype, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[39m\n\u001b[32m    886\u001b[39m         safetensors_metadata = f.metadata()\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m safetensors_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m safetensors_metadata.get(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mflax\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    889\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe safetensors archive passed at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_archive_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not contain the valid metadata.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    890\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Make sure you save your model with the `save_pretrained` method.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    891\u001b[39m         )\n\u001b[32m    892\u001b[39m     safetensors_from_pt = safetensors_metadata.get(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;66;03m# init random models\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: The safetensors archive passed at /Users/ridhibandaru/.cache/huggingface/hub/models--bendemonium--babylm-poincare-structformer/snapshots/eda60faed6eb06c5bb7917d88775709a388d59ec/model.safetensors does not contain the valid metadata. Make sure you save your model with the `save_pretrained` method."
     ]
    }
   ],
   "source": [
    "from transformers import FlaxAutoModel\n",
    "model = FlaxAutoModel.from_pretrained(\"bendemonium/babylm-poincare-structformer\",\n",
    "                                             trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import torch\n",
    "\n",
    "# with open(\"data/tokens/test_tokenized.pkl\", \"rb\") as f:\n",
    "#     tokenized_data = pickle.load(f)\n",
    "\n",
    "# input_ids = torch.tensor(tokenized_data[\"input_ids\"])\n",
    "# attention_mask = torch.tensor(tokenized_data[\"attention_mask\"])\n",
    "\n",
    "# model.eval()  # set to evaluation mode\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f23b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_parameters(only_trainable=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
