seed: 42

# ---- Model ----
vocab_name: gpt2            
max_length: 128             
hidden_dim: 256
num_layers: 6
num_heads: 8
dropout_rate: 0.1
c: 1.0                      # Poincare curvature (>0)
pad_id: null                # null because I want it to infer from the tokenizer

# ---- Training ----
training:
  max_words: 100_000_000    # stop after this many "words" (words = 0.75 * non-pad tokens)
  batch_size: 128
  eval_batch_size: 128
  eval_interval_words: 1_000_000  # run eval roughly every 1M words
  num_epochs: 4
  lr_ce: 2.0e-4             # non-embedding (Euclidean) params – AdamW
  lr_riem: 1.0e-4           # embedding table – AdamW + Riemannian conversion
  lambda_h: 0.05            # weight for local hyperbolic (adjacent) loss
  lambda_tree: 0.05         # weight for tree regularizer (if used)
  tau: 1.0                  # scale for tree distances (if used)

# ---- Data ----
data:
  type: pickle                # hf or pickle
  hf_repo_id: bendemonium/babylm25-bpe-tokens
  train_split: train
  val_split: dev 
  # pickle
  train_tokenized_repo: bendemonium/babylm25-bpe-tokens
  train_tokenized_file: train_tokeinzed.pkl
  val_tokenized_repo: bendemonium/babylm25-bpe-tokens
  val_tokenized_file: dev_tokenized.pkl

# ---- Checkpointing ----
checkpointing:
  output_repo_id: bendemonium/babylm-structformer-poincare # HF Hub model repo to push to
  branch_prefix: checkpoint
  include_modeling_files:
    - models/structformer_poincare.py
    - models/hyperbolic_geometry.py
    - utils/train_utils.py
    - utils/logging_utils.py
    - utils/save_utils.py
  model_file: models/structformer_poincare.py
  use_word_milestones: true   # for metadata purposes
  max_words: 100_000_000      # mirrored for save metadata

# ---- Logging ----
logging:
  log_dir: logs/structformer_run
  use_wandb: true
  wandb_project: structformer-flax
  wandb_run_name: run-babylm-poincare
  console_log_level: INFO
  file_log_level: DEBUG
  log_interval_steps: 900
  log_interval_words: 500000
  eval_log_interval: 1_000
  progress_bar: true
  words_per_second_window: 1000
  loss_spike_threshold: 2.0
  nan_alert: true
  memory_alert_threshold_gb: 8.0
